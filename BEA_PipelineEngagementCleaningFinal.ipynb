{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPUYvmTknsRFm6Ltv5SQUJQ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/caseyeaston/BEA_PipelineEngagementAnalysis/blob/main/BEA_PipelineEngagementCleaningFinal.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Main"
      ],
      "metadata": {
        "id": "n9Wy7FDaG6qj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# # Mount Google Drive\n",
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "LKl1obNgsqeX"
      },
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Import libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Display settings\n",
        "pd.set_option('display.max_columns', None)\n",
        "pd.set_option('display.max_rows', 100)\n",
        "pd.set_option('display.width', None)"
      ],
      "metadata": {
        "id": "1njSdg8Pss0Q"
      },
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define file paths\n",
        "base_path = '/content/drive/MyDrive/Work/BEA/2025 BEA Data Project Shared Folder/Data/(Main) Data Sources/Existing/PPBEA Pipeline/CSVs/'\n",
        "file_paths = {\n",
        "    '2019-2020': f'{base_path}2019-2020_PPBEA Pipeline_Engagement.csv',\n",
        "    '2020-2021': f'{base_path}2020-2021_PPBEA Pipeline_Engagement.csv',\n",
        "    '2021-2022': f'{base_path}2021-2022_PPBEA Pipeline_Engagement.csv',\n",
        "    '2022-2023': f'{base_path}2022-2023_PPBEA Pipeline_Engagement.csv',\n",
        "    '2023-2024': f'{base_path}2023-2024_PPBEA Pipeline_Engagement.csv',\n",
        "    '2024-2025': f'{base_path}2024-2025_PPBEA Pipeline_Engagement.csv',\n",
        "}\n",
        "\n",
        "# Load all CSV files\n",
        "dfs = {}\n",
        "for year, path in file_paths.items():\n",
        "    df = pd.read_csv(path)\n",
        "    df = df.dropna(how='all')  # Remove completely empty rows\n",
        "    df['School Year'] = year  # Add school year identifier\n",
        "    dfs[year] = df\n",
        "\n",
        "# Combine all dataframes\n",
        "dfmain = pd.concat(dfs.values(), ignore_index=True)"
      ],
      "metadata": {
        "id": "qku6mOr_tMZK"
      },
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Rename PPBEA Member to District\n",
        "dfmain = dfmain.rename(columns={'PPBEA Member': 'District'})"
      ],
      "metadata": {
        "id": "--cAFXytypfW"
      },
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Drop district columns and other unwanted columns\n",
        "columns_to_drop = [\n",
        "    ' ',  # Unnamed column\n",
        "    'Calhan District RJ-1', 'Harrison District 2', 'Widefield District 3',\n",
        "    'Fountain Ft.Carson District 8', 'Colorado Springs District 11',\n",
        "    'Cheyenne Mountain District 12', 'Manitou Springs District 14',\n",
        "    'Academy District 20', 'Ellicott District 22', 'Peyton District 23JT',\n",
        "    'Lewis Palmer District 38', 'El Paso County District 49',\n",
        "    'Colorado Springs Early College (CSEC)', 'CO Digital BOCES PPOS & CPA',\n",
        "    'Eastlake High School', 'Banning Lewis Ranch', 'Atlas Prep',\n",
        "    'Woodland Park School District',\n",
        "    'Unnamed: 24',\n",
        "    'Career Rep Email', 'Follow-up Task: ', 'Employer post Internship',\n",
        "    'Sponsor Email', 'Placed into Employment Post Internship',\n",
        "    'Staff Interactions with Businesses', 'Career Rep First Name',\n",
        "    'Career Rep Last Name', 'Opp Number', 'Task Number',\n",
        "    'PPBEA Staff Assigned', 'Next Action', 'PPBEA Notes',\n",
        "    'Notes: Student Name, Duration, School Name, Sponsor Name, Teacher Name, Flags'\n",
        "]\n",
        "dfmain = dfmain.drop(columns=columns_to_drop)"
      ],
      "metadata": {
        "id": "cc03uaaDtOPE"
      },
      "execution_count": 74,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Merge duplicate columns\n",
        "dfmain['Pro101 Certificates Earned'] = dfmain['Pro101 Certificates Earned'].fillna(\n",
        "    dfmain['Professionalism 101 Certificates Earned']\n",
        ")\n",
        "dfmain = dfmain.drop(columns=[\n",
        "    'Professionalism 101 Certificates Earned',\n",
        "])"
      ],
      "metadata": {
        "id": "S0IklkYRtQGj"
      },
      "execution_count": 75,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert numeric columns\n",
        "numeric_cols = [\n",
        "    'Complete Student Trainings',\n",
        "    'Complete Staff Trainings',\n",
        "    'Complete Student Interactions',\n",
        "    'Complete Student Internships',\n",
        "    'Internships in Progress',\n",
        "    'Pending Student Interactions',\n",
        "    'Declined or Cancelled Student Interactions',\n",
        "    'Pro101 Certificates Earned'\n",
        "]\n",
        "\n",
        "for col in numeric_cols:\n",
        "    dfmain[col] = pd.to_numeric(dfmain[col], errors='coerce')\n",
        "\n",
        "# Fill nulls with 0 for numeric columns\n",
        "for col in numeric_cols:\n",
        "    dfmain[col] = dfmain[col].fillna(0)"
      ],
      "metadata": {
        "id": "xMsl0xOhtSPr"
      },
      "execution_count": 76,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Remove summary and empty rows\n",
        "dfmain = dfmain[\n",
        "    ((dfmain['Complete Student Interactions'] <= 2000) | (dfmain['Complete Student Interactions'].isna())) &\n",
        "    (dfmain['Event Title'].notna())\n",
        "]"
      ],
      "metadata": {
        "id": "F2sQ9xRStTVt"
      },
      "execution_count": 77,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert date columns to datetime\n",
        "dfmain['Initiation Date'] = pd.to_datetime(dfmain['Initiation Date'], errors='coerce')\n",
        "dfmain['Status Update Date'] = pd.to_datetime(dfmain['Status Update Date'], errors='coerce')\n",
        "dfmain['Event Date or Start Date'] = pd.to_datetime(dfmain['Event Date or Start Date'], errors='coerce')"
      ],
      "metadata": {
        "id": "ghqTAKvyu6nf"
      },
      "execution_count": 78,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Standardize WBL Opportunity Type\n",
        "dfmain['WBL Opportunity Type'] = dfmain['WBL Opportunity Type'].replace({\n",
        "    \"Speaker's Bureau\": \"Speakers Bureau\"\n",
        "})\n",
        "\n",
        "# Drop one-off WBL type\n",
        "dfmain = dfmain[dfmain['WBL Opportunity Type'] != 'Jobs/Training/Apprenticeship']\n",
        "\n",
        "# Clean text columns (strip whitespace/newlines)\n",
        "dfmain = dfmain.copy()\n",
        "dfmain['Business Champion Name'] = dfmain['Business Champion Name'].str.strip()\n",
        "dfmain = dfmain.rename(columns={'Student and Sponsor\\nor School POC Name': 'Student Sponsor Name'})\n",
        "dfmain['Student Sponsor Name'] = dfmain['Student Sponsor Name'].str.strip()"
      ],
      "metadata": {
        "id": "V9HD_f3ubckR"
      },
      "execution_count": 79,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Checking shape\n",
        "dfmain.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oHewuA1fod71",
        "outputId": "c5f54a5d-de0c-4fc3-96c9-9b853f454578"
      },
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10068, 19)"
            ]
          },
          "metadata": {},
          "execution_count": 80
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Date Errors and Nulls"
      ],
      "metadata": {
        "id": "98vpbrd3IHDR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Fix unrealistic dates (before 2018)\n",
        "date_cols = ['Initiation Date', 'Status Update Date', 'Event Date or Start Date']\n",
        "cutoff_date = pd.Timestamp('2018-01-01')\n",
        "\n",
        "for col in date_cols:\n",
        "    unrealistic = dfmain[col] < cutoff_date\n",
        "    count = unrealistic.sum()\n",
        "    if count > 0:\n",
        "        print(f\"Setting {count} unrealistic dates to null in {col}\")\n",
        "        dfmain.loc[unrealistic, col] = pd.NaT\n",
        "\n",
        "# Fill remaining nulls in date columns using cascade logic\n",
        "dfmain['Initiation Date'] = dfmain['Initiation Date'].fillna(dfmain['Event Date or Start Date']).fillna(dfmain['Status Update Date'])\n",
        "dfmain['Status Update Date'] = dfmain['Status Update Date'].fillna(dfmain['Event Date or Start Date']).fillna(dfmain['Initiation Date'])\n",
        "\n",
        "# Create Derived Event Date column with fallback logic\n",
        "# Priority: Event Date or Start Date → Status Update Date → Initiation Date\n",
        "dfmain['Derived Event Date'] = dfmain['Event Date or Start Date'].fillna(\n",
        "    dfmain['Status Update Date']\n",
        ").fillna(\n",
        "    dfmain['Initiation Date']\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ASOzjm7_QCW3",
        "outputId": "a58c051d-6187-446d-d340-fb4e4c3b7f74"
      },
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Setting 4 unrealistic dates to null in Initiation Date\n",
            "Setting 7 unrealistic dates to null in Status Update Date\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 'Placement Status' Parent Column & Separating Declined/Cancelled"
      ],
      "metadata": {
        "id": "mj7s-SHWz9F7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create parent category column\n",
        "def categorize_placement_status(status):\n",
        "    if status == 'Completed':\n",
        "        return 'Completed'\n",
        "    elif status in ['Cancelled-COVID', 'Cancelled-Weather', 'Cancelled-Illness']:\n",
        "        return 'Cancelled'\n",
        "    elif status in ['Initial Contact Made', 'Pending-Scheduling', 'Scheduled Interview',\n",
        "    'Internship In Process', 'Scheduled Event (Pending Completion)']:\n",
        "        return 'Pending'\n",
        "    else:\n",
        "        return 'Declined'\n",
        "\n",
        "dfmain['Placement Status Category'] = dfmain['Placement Status'].apply(categorize_placement_status)\n",
        "\n",
        "# Verify\n",
        "dfmain['Placement Status Category'].value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 241
        },
        "id": "v233isnh1PWy",
        "outputId": "630aa515-ba0f-41d6-c147-f5e59b3b1026"
      },
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Placement Status Category\n",
              "Completed    7549\n",
              "Declined     2161\n",
              "Pending       277\n",
              "Cancelled      81\n",
              "Name: count, dtype: int64"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>count</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Placement Status Category</th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Completed</th>\n",
              "      <td>7549</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Declined</th>\n",
              "      <td>2161</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Pending</th>\n",
              "      <td>277</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Cancelled</th>\n",
              "      <td>81</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div><br><label><b>dtype:</b> int64</label>"
            ]
          },
          "metadata": {},
          "execution_count": 82
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create Cancelled column and split Declined/Cancelled\n",
        "dfmain['Cancelled Student Interactions'] = 0\n",
        "dfmain = dfmain.rename(columns={\n",
        "    'Declined or Cancelled Student Interactions': 'Declined Student Interactions'\n",
        "})\n",
        "\n",
        "# Move Cancelled values to correct column based on Placement Status Category\n",
        "cancelled_mask = dfmain['Placement Status Category'] == 'Cancelled'\n",
        "dfmain.loc[cancelled_mask, 'Cancelled Student Interactions'] = dfmain.loc[cancelled_mask, 'Declined Student Interactions']\n",
        "dfmain.loc[cancelled_mask, 'Declined Student Interactions'] = 0\n",
        "\n",
        "# Convert 'Cancelled Student Interactions' to float datatype\n",
        "dfmain['Cancelled Student Interactions'] = dfmain['Cancelled Student Interactions'].astype(float)\n",
        "\n",
        "# Redefine numeric columns\n",
        "numeric_cols = [\n",
        "    'Complete Student Trainings',\n",
        "    'Complete Staff Trainings',\n",
        "    'Complete Student Interactions',\n",
        "    'Complete Student Internships',\n",
        "    'Internships in Progress',\n",
        "    'Pending Student Interactions',\n",
        "    'Declined Student Interactions',\n",
        "    'Cancelled Student Interactions',\n",
        "    'Pro101 Certificates Earned'\n",
        "]"
      ],
      "metadata": {
        "id": "Gu14y8tVPewQ"
      },
      "execution_count": 83,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Pro101"
      ],
      "metadata": {
        "id": "W5PjFE61sB4q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# from rapidfuzz import fuzz\n",
        "\n",
        "# # Extract student name (before \"/\") from Student Sponsor Name\n",
        "# def extract_student_name(name):\n",
        "#     if pd.isna(name):\n",
        "#         return ''\n",
        "#     name_str = str(name)\n",
        "#     if '/' in name_str:\n",
        "#         return name_str.split('/')[0].strip()\n",
        "#     else:\n",
        "#         return name_str.strip()\n",
        "\n",
        "# # Add temporary column for student names\n",
        "# dfmain['Student Name'] = dfmain['Student Sponsor Name'].apply(extract_student_name)\n",
        "\n",
        "# # Find rows with Pro101 cert earned during other events\n",
        "# pro101_during_other_event = dfmain[\n",
        "#     (dfmain['Pro101 Certificates Earned'] > 0) &\n",
        "#     (dfmain['WBL Opportunity Type'] != 'Professionalism 101 Training')\n",
        "# ]\n",
        "\n",
        "# print(f\"Rows with Pro101 cert earned during OTHER events: {len(pro101_during_other_event)}\")\n",
        "\n",
        "# # Check if any already have matching standalone Pro101 rows\n",
        "# potential_duplicates = []\n",
        "\n",
        "# for idx, row in pro101_during_other_event.iterrows():\n",
        "#     # Get student name from this row\n",
        "#     student_name = row['Student Name']\n",
        "\n",
        "#     if not student_name:  # Skip if no student name\n",
        "#         continue\n",
        "\n",
        "#     # Look for Pro101 Training rows with fuzzy match on student name\n",
        "#     pro101_rows = dfmain[dfmain['WBL Opportunity Type'] == 'Professionalism 101 Training']\n",
        "\n",
        "#     for pro101_idx, pro101_row in pro101_rows.iterrows():\n",
        "#         pro101_student_name = pro101_row['Student Name']\n",
        "\n",
        "#         if not pro101_student_name:\n",
        "#             continue\n",
        "\n",
        "#         # Fuzzy match on student names\n",
        "#         similarity = fuzz.ratio(student_name.lower(), pro101_student_name.lower())\n",
        "\n",
        "#         if similarity >= 85:  # 85% threshold\n",
        "#             potential_duplicates.append((idx, pro101_idx, similarity))\n",
        "#             break  # Found a match, move to next row\n",
        "\n",
        "# print(f\"\\nRows that already have standalone Pro101 records: {len(potential_duplicates)}\")\n",
        "\n",
        "# if len(potential_duplicates) > 0:\n",
        "#     print(\"\\nSample matches (first 10):\")\n",
        "#     for orig_idx, pro101_idx, similarity in potential_duplicates[:10]:\n",
        "#         print(f\"\\nOriginal event row {orig_idx} matches Pro101 row {pro101_idx} (similarity: {similarity}%)\")\n",
        "#         print(f\"  Original: {dfmain.loc[orig_idx, 'Student Name']} - {dfmain.loc[orig_idx, 'WBL Opportunity Type']}\")\n",
        "#         print(f\"  Pro101:   {dfmain.loc[pro101_idx, 'Student Name']} - {dfmain.loc[pro101_idx, 'WBL Opportunity Type']}\")"
      ],
      "metadata": {
        "id": "Biud2DCf75_1"
      },
      "execution_count": 84,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Drop the 2 existing Pro101 rows that we'll recreate from their matching events (found using fuzzy matching above)\n",
        "dfmain = dfmain.drop([1098, 540])\n",
        "\n",
        "# Find rows that need to be split (Pro101 earned during another event)\n",
        "rows_to_split = dfmain[\n",
        "    (dfmain['Pro101 Certificates Earned'] > 0) &\n",
        "    (dfmain['WBL Opportunity Type'] != 'Professionalism 101 Training')\n",
        "].copy()\n",
        "\n",
        "# Create new Pro101 rows\n",
        "new_pro101_rows = []\n",
        "\n",
        "for idx, row in rows_to_split.iterrows():\n",
        "    pro101_row = row.copy()\n",
        "    pro101_row['Placement Status'] = 'Completed'\n",
        "    pro101_row['Placement Status Category'] = 'Completed'\n",
        "    pro101_row['Business Champion Name'] = 'PPBEA'\n",
        "    pro101_row['Event Title'] = 'PPBEA Professionalism 101 Course'\n",
        "    pro101_row['WBL Opportunity Type'] = 'Professionalism 101 Training'\n",
        "    pro101_row['Complete Student Interactions'] = 1\n",
        "    pro101_row['Complete Student Trainings'] = 0\n",
        "    pro101_row['Complete Staff Trainings'] = 0\n",
        "    pro101_row['Complete Student Internships'] = 0\n",
        "    pro101_row['Internships in Progress'] = 0\n",
        "    pro101_row['Pending Student Interactions'] = 0\n",
        "    pro101_row['Declined Student Interactions'] = 0\n",
        "    pro101_row['Cancelled Student Interactions'] = 0\n",
        "    pro101_row['Pro101 Certificates Earned'] = 0\n",
        "    new_pro101_rows.append(pro101_row)\n",
        "\n",
        "# Add new Pro101 rows to dfmain\n",
        "dfmain = pd.concat([dfmain, pd.DataFrame(new_pro101_rows)], ignore_index=True)\n",
        "\n",
        "# Transfer 'Pro101 Certificated Earned' to 'Complete Student Interactions'\n",
        "pro101_completed_wrong = dfmain[\n",
        "    (dfmain['Placement Status'] == 'Completed') &\n",
        "    (dfmain['WBL Opportunity Type'] == 'Professionalism 101 Training') &\n",
        "    (dfmain['Complete Student Interactions'] == 0)\n",
        "]\n",
        "\n",
        "dfmain.loc[pro101_completed_wrong.index, 'Complete Student Interactions'] = 1\n",
        "\n",
        "# Drop Pro101 column (no longer needed)\n",
        "dfmain = dfmain.drop(columns=['Pro101 Certificates Earned'])\n",
        "\n",
        "print(f\"Created {len(new_pro101_rows)} new Pro101 rows\")\n",
        "dfmain.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bbq3upO8KKFN",
        "outputId": "2e8fc9cd-8e1d-4097-99e0-7397834f8235"
      },
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Created 61 new Pro101 rows\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10127, 21)"
            ]
          },
          "metadata": {},
          "execution_count": 85
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Placement Status & Numeric Columns Mismatch"
      ],
      "metadata": {
        "id": "Fc6r5G58MOf-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Redefine numeric columns\n",
        "numeric_cols = [\n",
        "    'Complete Student Trainings',\n",
        "    'Complete Staff Trainings',\n",
        "    'Complete Student Interactions',\n",
        "    'Complete Student Internships',\n",
        "    'Internships in Progress',\n",
        "    'Pending Student Interactions',\n",
        "    'Declined Student Interactions',\n",
        "    'Cancelled Student Interactions',\n",
        "]\n",
        "\n",
        "# Fix double-counting: rows with values in multiple numeric columns\n",
        "dfmain['num_cols_with_values'] = (dfmain[numeric_cols] > 0).sum(axis=1)\n",
        "rows_with_multiple = dfmain['num_cols_with_values'] > 1\n",
        "\n",
        "# Zero out Complete Student Interactions for rows with Trainings + Interactions\n",
        "dfmain.loc[rows_with_multiple, 'Complete Student Interactions'] = 0\n",
        "\n",
        "# Drop helper column\n",
        "dfmain = dfmain.drop(columns=['num_cols_with_values'])\n",
        "\n",
        "# Create a column for numeric sum\n",
        "dfmain['_numeric_sum'] = dfmain[numeric_cols].sum(axis=1)"
      ],
      "metadata": {
        "id": "Z8vpk5my3EJc"
      },
      "execution_count": 86,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Fill All-Zero Rows with Minimum Values"
      ],
      "metadata": {
        "id": "TkzfvSGz4dGQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Find all-zero rows\n",
        "all_zeros = (dfmain[numeric_cols] == 0).all(axis=1)\n",
        "\n",
        "# Calculate minimum numeric sum by WBL Opportunity Type (excluding zeros)\n",
        "wbl_minimums = dfmain[dfmain['_numeric_sum'] > 0].groupby('WBL Opportunity Type')['_numeric_sum'].min()\n",
        "\n",
        "# Get WBL types that have all-zero rows\n",
        "wbl_types_with_zeros = dfmain[all_zeros]['WBL Opportunity Type'].unique()\n",
        "\n",
        "print(\"Minimum values by WBL Opportunity Type (for types with all-zero rows):\")\n",
        "for wbl_type in sorted(wbl_types_with_zeros):\n",
        "    if pd.notna(wbl_type):\n",
        "        min_val = wbl_minimums.get(wbl_type, 1)\n",
        "        print(f\"  {wbl_type}: {min_val}\")\n",
        "\n",
        "# Show value counts of WBL Opportunity Type for all-zero rows\n",
        "print(\"\\nWBL Opportunity Type breakdown for all-zero rows:\")\n",
        "print(dfmain[all_zeros]['WBL Opportunity Type'].value_counts())\n",
        "print(f\"\\nTotal all-zero rows: {all_zeros.sum()}\")\n",
        "\n",
        "# WBL Opportunity Type to numeric column mapping (Completed)\n",
        "wbl_to_column_map_completed = {\n",
        "    'Staff Training': 'Complete Staff Trainings',\n",
        "    'Regional Advisory Meeting': 'Complete Staff Trainings',\n",
        "    'Site Visit - Staff': 'Complete Staff Trainings',\n",
        "    'Student Training': 'Complete Student Trainings',\n",
        "    'Professionalism 101 Training': 'Complete Student Interactions',\n",
        "    'Informational Interview Video': 'Complete Student Interactions',\n",
        "    'Career Story Video': 'Complete Student Interactions',\n",
        "    'e-WBL Informational Interview': 'Complete Student Interactions',\n",
        "    'e-WBL Class Presentation': 'Complete Student Interactions',\n",
        "    'Job Fair': 'Complete Student Interactions',\n",
        "    'Class/Group Mentorship': 'Complete Student Interactions',\n",
        "    'Industry Sponsored Project': 'Complete Student Interactions',\n",
        "    'Class Presentation': 'Complete Student Interactions',\n",
        "    'Job Shadow': 'Complete Student Interactions',\n",
        "    'Site Visit': 'Complete Student Interactions',\n",
        "    'Speakers Bureau': 'Complete Student Interactions',\n",
        "    'Event': 'Complete Student Interactions',\n",
        "    'Individual Mentorship': 'Complete Student Interactions',\n",
        "    'Paid Job': 'Complete Student Interactions',\n",
        "    'Internship 60': 'Complete Student Internships',\n",
        "    'Internship 120': 'Complete Student Internships',\n",
        "    'Internship 320': 'Complete Student Internships',\n",
        "    'Apprenticeship': 'Complete Student Internships',\n",
        "}\n",
        "\n",
        "# WBL Opportunity Type to numeric column mapping (Pending)\n",
        "wbl_to_column_map_pending = {\n",
        "    'Professionalism 101 Training': 'Pending Student Interactions',\n",
        "    'Career Story Video': 'Pending Student Interactions',\n",
        "    'e-WBL Informational Interview': 'Pending Student Interactions',\n",
        "    'Industry Sponsored Project': 'Pending Student Interactions',\n",
        "    'Class Presentation': 'Pending Student Interactions',\n",
        "    'Job Shadow': 'Pending Student Interactions',\n",
        "    'Site Visit': 'Pending Student Interactions',\n",
        "    'Speakers Bureau': 'Pending Student Interactions',\n",
        "    'Event': 'Pending Student Interactions',\n",
        "    'Internship 60': 'Internships in Progress',\n",
        "    'Internship 120': 'Internships in Progress',\n",
        "    'Internship 320': 'Internships in Progress',\n",
        "    'Apprenticeship': 'Internships in Progress',\n",
        "}\n",
        "\n",
        "# Fill all-zero rows with minimum values\n",
        "for idx in dfmain[all_zeros].index:\n",
        "    row = dfmain.loc[idx]\n",
        "    wbl_type = row['WBL Opportunity Type']\n",
        "    category = row['Placement Status Category']\n",
        "\n",
        "    # Get minimum value for this WBL type (default to 1 if no minimum available)\n",
        "    min_value = wbl_minimums.get(wbl_type, 1)\n",
        "\n",
        "    if category == 'Completed':\n",
        "        if wbl_type in wbl_to_column_map_completed:\n",
        "            dfmain.loc[idx, wbl_to_column_map_completed[wbl_type]] = min_value\n",
        "    elif category == 'Pending':\n",
        "        if wbl_type in wbl_to_column_map_pending:\n",
        "            dfmain.loc[idx, wbl_to_column_map_pending[wbl_type]] = min_value\n",
        "    elif category == 'Declined':\n",
        "        dfmain.loc[idx, 'Declined Student Interactions'] = min_value\n",
        "    elif category == 'Cancelled':\n",
        "        dfmain.loc[idx, 'Cancelled Student Interactions'] = min_value\n",
        "\n",
        "# Drop temporary numeric sum column\n",
        "dfmain = dfmain.drop(columns=['_numeric_sum'])\n",
        "\n",
        "# Verify\n",
        "all_zeros_after = (dfmain[numeric_cols] == 0).all(axis=1)\n",
        "print(f\"\\nAll-zero rows before filling: {all_zeros.sum()}\")\n",
        "print(f\"All-zero rows after filling: {all_zeros_after.sum()}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rX3hbpXk4SHL",
        "outputId": "71512e3f-dbef-4dcc-ccb5-eb43a6c67b46"
      },
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Minimum values by WBL Opportunity Type (for types with all-zero rows):\n",
            "  Apprenticeship: 1.0\n",
            "  Career Story Video: 1.0\n",
            "  Class Presentation: 1.0\n",
            "  Event: 1.0\n",
            "  Industry Sponsored Project: 1.0\n",
            "  Internship 60: 1.0\n",
            "  Job Shadow: 1.0\n",
            "  Professionalism 101 Training: 1.0\n",
            "  Regional Advisory Meeting: 1\n",
            "  Site Visit: 1.0\n",
            "  Site Visit - Staff: 1\n",
            "  Speakers Bureau: 10.0\n",
            "  Student Training: 1.0\n",
            "  e-WBL Class Presentation: 1.0\n",
            "  e-WBL Informational Interview: 1.0\n",
            "\n",
            "WBL Opportunity Type breakdown for all-zero rows:\n",
            "WBL Opportunity Type\n",
            "Speakers Bureau                  489\n",
            "Professionalism 101 Training     141\n",
            "Site Visit                       134\n",
            "Class Presentation                98\n",
            "e-WBL Class Presentation          91\n",
            "Internship 60                     62\n",
            "Regional Advisory Meeting         42\n",
            "Student Training                   9\n",
            "Job Shadow                         8\n",
            "Event                              5\n",
            "e-WBL Informational Interview      5\n",
            "Site Visit - Staff                 4\n",
            "Industry Sponsored Project         1\n",
            "Career Story Video                 1\n",
            "Apprenticeship                     1\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Total all-zero rows: 1091\n",
            "\n",
            "All-zero rows before filling: 1091\n",
            "All-zero rows after filling: 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Duplicate Handling & Pending Events"
      ],
      "metadata": {
        "id": "ZPZYqUnN3Nga"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define base matching fields for duplicate detection\n",
        "base_match_fields = [\n",
        "    'Business Champion Name',\n",
        "    'Student Sponsor Name',\n",
        "    'WBL Opportunity Type',\n",
        "    'District',\n",
        "    'Event Title',\n",
        "    'School or Program Site'\n",
        "]\n",
        "\n",
        "# Create temporary column for numeric sum\n",
        "dfmain['_numeric_sum'] = dfmain[numeric_cols].sum(axis=1)\n",
        "\n",
        "# Find duplicates and decide which to keep\n",
        "rows_to_drop = []\n",
        "\n",
        "for idx in dfmain.index:\n",
        "    row = dfmain.loc[idx]\n",
        "\n",
        "    # Look for matches in earlier rows\n",
        "    matches = dfmain[\n",
        "        (dfmain.index < idx) &\n",
        "        (dfmain['Business Champion Name'] == row['Business Champion Name']) &\n",
        "        (dfmain['Student Sponsor Name'] == row['Student Sponsor Name']) &\n",
        "        (dfmain['WBL Opportunity Type'] == row['WBL Opportunity Type']) &\n",
        "        (dfmain['District'] == row['District']) &\n",
        "        (dfmain['Event Title'] == row['Event Title']) &\n",
        "        (dfmain['School or Program Site'] == row['School or Program Site']) &\n",
        "        (dfmain['_numeric_sum'] == row['_numeric_sum']) &\n",
        "        (\n",
        "            (dfmain['Initiation Date'] == row['Initiation Date']) |\n",
        "            (dfmain['Derived Event Date'] == row['Derived Event Date'])\n",
        "        )\n",
        "    ]\n",
        "\n",
        "    if len(matches) > 0:\n",
        "        orig_idx = matches.index[0]\n",
        "        orig_status = dfmain.loc[orig_idx, 'Placement Status']\n",
        "        dup_status = row['Placement Status']\n",
        "\n",
        "        # Rule 1: Prefer 'Completed' status\n",
        "        if orig_status == 'Completed' and dup_status != 'Completed':\n",
        "            rows_to_drop.append(idx)\n",
        "        elif dup_status == 'Completed' and orig_status != 'Completed':\n",
        "            rows_to_drop.append(orig_idx)\n",
        "        else:\n",
        "            # Rule 2: Choose the one with least nulls\n",
        "            orig_null_count = dfmain.loc[orig_idx].isna().sum()\n",
        "            dup_null_count = row.isna().sum()\n",
        "\n",
        "            if orig_null_count < dup_null_count:\n",
        "                rows_to_drop.append(idx)\n",
        "            elif dup_null_count < orig_null_count:\n",
        "                rows_to_drop.append(orig_idx)\n",
        "            else:\n",
        "                # Rule 3: Keep the most recent based on Derived Event Date\n",
        "                orig_date = dfmain.loc[orig_idx, 'Derived Event Date']\n",
        "                dup_date = row['Derived Event Date']\n",
        "\n",
        "                if pd.isna(orig_date) and pd.isna(dup_date):\n",
        "                    rows_to_drop.append(idx)\n",
        "                elif pd.isna(orig_date):\n",
        "                    rows_to_drop.append(orig_idx)\n",
        "                elif pd.isna(dup_date):\n",
        "                    rows_to_drop.append(idx)\n",
        "                elif dup_date > orig_date:\n",
        "                    rows_to_drop.append(orig_idx)\n",
        "                else:\n",
        "                    rows_to_drop.append(idx)\n",
        "\n",
        "# Remove duplicates from rows_to_drop list\n",
        "rows_to_drop = list(set(rows_to_drop))\n",
        "\n",
        "# Drop duplicates\n",
        "dfmain = dfmain.drop(rows_to_drop)\n",
        "\n",
        "# Drop temporary numeric sum column\n",
        "dfmain = dfmain.drop(columns=['_numeric_sum'])"
      ],
      "metadata": {
        "id": "8KCLK8XSiuAn"
      },
      "execution_count": 88,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Fix 2019-2020 Internship rows marked as Declined that should be Completed\n",
        "declined_should_be_completed = dfmain[\n",
        "    (dfmain['Placement Status Category'] == 'Declined') &\n",
        "    (dfmain['School Year'] == '2019-2020') &\n",
        "    (dfmain['WBL Opportunity Type'].isin(['Internship 60', 'Internship 120', 'Internship 320'])) &\n",
        "    (dfmain['Complete Student Interactions'] > 0)\n",
        "].index\n",
        "\n",
        "dfmain.loc[declined_should_be_completed, 'Placement Status'] = 'Completed'\n",
        "dfmain.loc[declined_should_be_completed, 'Placement Status Category'] = 'Completed'\n",
        "dfmain.loc[declined_should_be_completed, 'Complete Student Internships'] = dfmain.loc[declined_should_be_completed, 'Complete Student Interactions']\n",
        "dfmain.loc[declined_should_be_completed, 'Complete Student Interactions'] = 0\n",
        "\n",
        "# Mark 'Internship In Process' 2024-2025 rows as 'Completed'\n",
        "internship_2024_25 = (\n",
        "    (dfmain['Placement Status'] == 'Internship In Process') &\n",
        "    (dfmain['School Year'] == '2024-2025')\n",
        ")\n",
        "dfmain.loc[internship_2024_25, 'Placement Status'] = 'Completed'\n",
        "\n",
        "# Transfer internship counts to Complete Student Internships for these rows\n",
        "dfmain.loc[internship_2024_25, 'Complete Student Internships'] = dfmain.loc[internship_2024_25, 'Internships in Progress']\n",
        "dfmain.loc[internship_2024_25, 'Internships in Progress'] = 0\n",
        "\n",
        "# Reclassify remaining pending statuses as \"Declined - Unfinished\"\n",
        "pending_statuses = [\n",
        "    'Initial Contact Made', 'Pending-Scheduling', 'Scheduled Interview',\n",
        "    'Internship In Process', 'Scheduled Event (Pending Completion)'\n",
        "]\n",
        "dfmain.loc[dfmain['Placement Status'].isin(pending_statuses), 'Placement Status'] = 'Declined - Unfinished'\n",
        "\n",
        "# Transfer pending counts to declined counts for reclassified rows\n",
        "dfmain.loc[\n",
        "    dfmain['Placement Status'] == 'Declined - Unfinished',\n",
        "    'Declined Student Interactions'\n",
        "] = (\n",
        "    dfmain.loc[dfmain['Placement Status'] == 'Declined - Unfinished', 'Pending Student Interactions'] +\n",
        "    dfmain.loc[dfmain['Placement Status'] == 'Declined - Unfinished', 'Internships in Progress']\n",
        ")\n",
        "\n",
        "# Zero out the pending columns for these rows\n",
        "dfmain.loc[dfmain['Placement Status'] == 'Declined - Unfinished', 'Pending Student Interactions'] = 0\n",
        "dfmain.loc[dfmain['Placement Status'] == 'Declined - Unfinished', 'Internships in Progress'] = 0\n",
        "\n",
        "# Drop the now-irrelevant pending columns\n",
        "dfmain = dfmain.drop(columns=['Pending Student Interactions', 'Internships in Progress'])\n",
        "\n",
        "# Match Placement Status Category with new Placement Status: 'Declined - Unfinished'\n",
        "dfmain['Placement Status Category'] = dfmain['Placement Status'].apply(categorize_placement_status)\n",
        "\n",
        "# Verify\n",
        "print(f\"Rows dropped as duplicates: {len(rows_to_drop)}\")\n",
        "print(f\"Final row count: {len(dfmain)}\")\n",
        "print(f\"\\nPlacement Status counts:\\n\")\n",
        "print(dfmain['Placement Status Category'].value_counts(), \"\\n\")\n",
        "print(dfmain['Placement Status'].value_counts())"
      ],
      "metadata": {
        "id": "Vm-68dYPDLHq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3ffbc88a-85e6-41a8-ce7b-bd36f15101dd"
      },
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Rows dropped as duplicates: 209\n",
            "Final row count: 9918\n",
            "\n",
            "Placement Status counts:\n",
            "\n",
            "Placement Status Category\n",
            "Completed    7644\n",
            "Declined     2193\n",
            "Cancelled      81\n",
            "Name: count, dtype: int64 \n",
            "\n",
            "Placement Status\n",
            "Completed                           7644\n",
            "Declined-Applicant                   475\n",
            "Declined - Business Unresponsive     225\n",
            "Declined/Cancelled-Other             224\n",
            "Declined-Business Scheduling         220\n",
            "Declined-Business                    210\n",
            "Declined- Student Applicant          181\n",
            "Declined - Student Profile           176\n",
            "Declined - Student Other             113\n",
            "Declined - Student Unresponsive       90\n",
            "Declined - Staff Scheduling           76\n",
            "Declined-Intern NOT Selected          66\n",
            "Cancelled-COVID                       63\n",
            "Declined - Unfinished                 38\n",
            "Declined - Staff Applicant            35\n",
            "Declined - Staff Unresponsive         26\n",
            "Declined-Opportunity FULL             24\n",
            "Cancelled-Weather                     17\n",
            "Terminated                            14\n",
            "Cancelled-Illness                      1\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Standardizing District Names and Reorganize Column Structure"
      ],
      "metadata": {
        "id": "suD1pQZpQGew"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Standardize District Names\n",
        "\n",
        "district_mapping = {\n",
        "    'D11': 'Colorado Springs (D11)',\n",
        "    'D20': 'Academy (D20)',\n",
        "    'D49': 'El Paso County (D49)',\n",
        "    'D2': 'Harrison (D2)',\n",
        "    'D3': 'Widefield (D3)',\n",
        "    'D8': 'Fountain-Fort Carson (D8)',\n",
        "    'D12': 'Cheyenne Mountain (D12)',\n",
        "    'D14': 'Manitou Springs (D14)',\n",
        "    'D38': 'Lewis-Palmer (D38)',\n",
        "    'CEC-CS': 'Colorado Springs Early College (CEC-CS)',\n",
        "    'BLR': 'Banning Lewis Ranch (BLR)',\n",
        "    'WPSD': 'Woodland Park (WPSD)',\n",
        "    'Ellicott': 'Ellicott (D22)',\n",
        "    'Peyton': 'Peyton (D23JT)',\n",
        "    'Calhan': 'Calhan (RJ-1)',\n",
        "    'Atlas Prep': 'Atlas Preparatory',\n",
        "    'CPA/PPOS': 'CO Digital BOCES (CPA/PPOS)',\n",
        "    'PTEC': 'Power Technical (PTEC)',\n",
        "    'Goal H.S.': 'Goal High School',\n",
        "    'Mon Impact': 'Monumental Impact',\n",
        "    'Peak Ed': 'Peak Education',\n",
        "    'Miami-Yoder': 'Miami-Yoder (JT-60)',\n",
        "    'ECA': 'Evangel Christian Academy',\n",
        "    'MET': 'Mountain Employment Training',\n",
        "    'TCA': 'The Classical Academy',\n",
        "    'CCV': 'Cripple Creek-Victor (RE-1)',\n",
        "    'DYS': 'Division of Youth Services',\n",
        "    'Vanguard': 'Vanguard School',\n",
        "    'Homeschool': 'Homeschool',\n",
        "    'Various': 'Various',\n",
        "    'BBBS': 'Big Brothers Big Sisters',\n",
        "    'Roundup': 'Roundup School'\n",
        "}\n",
        "\n",
        "dfmain['District'] = dfmain['District'].replace(district_mapping)\n",
        "\n",
        "# Reorganize Column Structure\n",
        "\n",
        "column_order = [\n",
        "    'School Year',\n",
        "    'Derived Event Date',\n",
        "    'Placement Status Category',\n",
        "    'Placement Status',\n",
        "    'WBL Opportunity Type',\n",
        "    'Event Title',\n",
        "    'Business Champion Name',\n",
        "    'Student Sponsor Name',\n",
        "    'District',\n",
        "    'School or Program Site',\n",
        "    'Complete Student Interactions',\n",
        "    'Complete Student Trainings',\n",
        "    'Complete Student Internships',\n",
        "    'Declined Student Interactions',\n",
        "    'Cancelled Student Interactions',\n",
        "    'Complete Staff Trainings',\n",
        "    'Initiation Date',\n",
        "    'Status Update Date',\n",
        "    'Event Date or Start Date',\n",
        "]\n",
        "\n",
        "dfmain = dfmain[column_order]"
      ],
      "metadata": {
        "id": "l3z7dB8YQJo6"
      },
      "execution_count": 90,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Final Data Summary"
      ],
      "metadata": {
        "id": "DdY40u6EPixE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"=\" * 60)\n",
        "print(\"FINAL DATASET SUMMARY\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "# Size\n",
        "print(f\"\\nSize: {dfmain.shape[0]:,} rows × {dfmain.shape[1]} columns\")\n",
        "\n",
        "# Date Range\n",
        "print(f\"\\nDate Range: {dfmain['Derived Event Date'].min().strftime('%B %d, %Y')} - {dfmain['Derived Event Date'].max().strftime('%B %d, %Y')}\")\n",
        "\n",
        "# Records by Year\n",
        "print(\"\\nRecords by Year:\")\n",
        "year_counts = dfmain['School Year'].value_counts().sort_index()\n",
        "for year, count in year_counts.items():\n",
        "    print(f\"  {year}: {count:,}\")\n",
        "\n",
        "# Status Distribution (by Category)\n",
        "print(\"\\nStatus Distribution (by Category):\")\n",
        "status_counts = dfmain['Placement Status Category'].value_counts()\n",
        "for status, count in status_counts.items():\n",
        "    pct = count / len(dfmain) * 100\n",
        "    print(f\"  {status}: {count:,} ({pct:.1f}%)\")\n",
        "\n",
        "# Status Distribution (detailed)\n",
        "print(\"\\nStatus Distribution (detailed):\")\n",
        "detailed_status = dfmain['Placement Status'].value_counts()\n",
        "for status, count in detailed_status.items():\n",
        "    pct = count / len(dfmain) * 100\n",
        "    print(f\"  {status}: {count:,} ({pct:.1f}%)\")\n",
        "\n",
        "# Student Engagement Metrics\n",
        "print(\"\\nStudent Engagement Metrics:\")\n",
        "total_completed = dfmain['Complete Student Interactions'].sum() + dfmain['Complete Student Trainings'].sum() + dfmain['Complete Student Internships'].sum()\n",
        "total_declined = dfmain['Declined Student Interactions'].sum()\n",
        "total_cancelled = dfmain['Cancelled Student Interactions'].sum()\n",
        "grand_total = total_completed + total_declined + total_cancelled\n",
        "\n",
        "print(f\"  Total Completed: {total_completed:,.0f}\")\n",
        "print(f\"  Total Declined: {total_declined:,.0f}\")\n",
        "print(f\"  Total Cancelled: {total_cancelled:,.0f}\")\n",
        "print(f\"  Grand Total: {grand_total:,.0f} student engagements\")\n",
        "\n",
        "# Average students per completed event\n",
        "completed_events = dfmain[dfmain['Placement Status Category'] == 'Completed']\n",
        "avg_students = total_completed / len(completed_events) if len(completed_events) > 0 else 0\n",
        "print(f\"  Average Students per Completed Event: {avg_students:.1f}\")\n",
        "\n",
        "# Staff Metrics\n",
        "print(\"\\nStaff Metrics:\")\n",
        "print(f\"  Staff Trainings: {dfmain['Complete Staff Trainings'].sum():,.0f}\")\n",
        "\n",
        "# Top 5 Districts\n",
        "print(\"\\nTop 5 Districts:\")\n",
        "top_districts = dfmain['District'].value_counts().head(5)\n",
        "for i, (district, count) in enumerate(top_districts.items(), 1):\n",
        "    print(f\"  {i}. {district}: {count:,} events\")\n",
        "\n",
        "# Top 5 WBL Types\n",
        "print(\"\\nTop 5 WBL Opportunity Types:\")\n",
        "top_wbl = dfmain['WBL Opportunity Type'].value_counts().head(5)\n",
        "for i, (wbl, count) in enumerate(top_wbl.items(), 1):\n",
        "    print(f\"  {i}. {wbl}: {count:,} events\")\n",
        "\n",
        "# Top 5 Businesses\n",
        "print(\"\\nTop 5 Business Partners:\")\n",
        "top_business = dfmain['Business Champion Name'].value_counts().head(5)\n",
        "for i, (business, count) in enumerate(top_business.items(), 1):\n",
        "    print(f\"  {i}. {business}: {count:,} events\")\n",
        "\n",
        "print(\"\\n\" + \"=\" * 60)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3lg_wC-ePig4",
        "outputId": "5e57b154-9265-4eb4-f3ed-986e5aafe4ad"
      },
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================================================\n",
            "FINAL DATASET SUMMARY\n",
            "============================================================\n",
            "\n",
            "Size: 9,918 rows × 19 columns\n",
            "\n",
            "Date Range: January 07, 2019 - September 22, 2025\n",
            "\n",
            "Records by Year:\n",
            "  2019-2020: 309\n",
            "  2020-2021: 1,926\n",
            "  2021-2022: 1,993\n",
            "  2022-2023: 2,743\n",
            "  2023-2024: 1,502\n",
            "  2024-2025: 1,445\n",
            "\n",
            "Status Distribution (by Category):\n",
            "  Completed: 7,644 (77.1%)\n",
            "  Declined: 2,193 (22.1%)\n",
            "  Cancelled: 81 (0.8%)\n",
            "\n",
            "Status Distribution (detailed):\n",
            "  Completed: 7,644 (77.1%)\n",
            "  Declined-Applicant: 475 (4.8%)\n",
            "  Declined - Business Unresponsive: 225 (2.3%)\n",
            "  Declined/Cancelled-Other: 224 (2.3%)\n",
            "  Declined-Business Scheduling: 220 (2.2%)\n",
            "  Declined-Business: 210 (2.1%)\n",
            "  Declined- Student Applicant: 181 (1.8%)\n",
            "  Declined - Student Profile: 176 (1.8%)\n",
            "  Declined - Student Other: 113 (1.1%)\n",
            "  Declined - Student Unresponsive: 90 (0.9%)\n",
            "  Declined - Staff Scheduling: 76 (0.8%)\n",
            "  Declined-Intern NOT Selected: 66 (0.7%)\n",
            "  Cancelled-COVID: 63 (0.6%)\n",
            "  Declined - Unfinished: 38 (0.4%)\n",
            "  Declined - Staff Applicant: 35 (0.4%)\n",
            "  Declined - Staff Unresponsive: 26 (0.3%)\n",
            "  Declined-Opportunity FULL: 24 (0.2%)\n",
            "  Cancelled-Weather: 17 (0.2%)\n",
            "  Terminated: 14 (0.1%)\n",
            "  Cancelled-Illness: 1 (0.0%)\n",
            "\n",
            "Student Engagement Metrics:\n",
            "  Total Completed: 50,856\n",
            "  Total Declined: 8,742\n",
            "  Total Cancelled: 1,764\n",
            "  Grand Total: 61,362 student engagements\n",
            "  Average Students per Completed Event: 6.7\n",
            "\n",
            "Staff Metrics:\n",
            "  Staff Trainings: 1,382\n",
            "\n",
            "Top 5 Districts:\n",
            "  1. Colorado Springs (D11): 3,246 events\n",
            "  2. Academy (D20): 1,316 events\n",
            "  3. El Paso County (D49): 1,302 events\n",
            "  4. Fountain-Fort Carson (D8): 755 events\n",
            "  5. Widefield (D3): 711 events\n",
            "\n",
            "Top 5 WBL Opportunity Types:\n",
            "  1. Professionalism 101 Training: 3,807 events\n",
            "  2. e-WBL Informational Interview: 1,498 events\n",
            "  3. Job Shadow: 1,167 events\n",
            "  4. Internship 60: 964 events\n",
            "  5. Speakers Bureau: 752 events\n",
            "\n",
            "Top 5 Business Partners:\n",
            "  1. PPBEA: 4,213 events\n",
            "  2. UCCS College of Nursing & Health Sciences: 308 events\n",
            "  3. Children’s Hospital Colorado, Colorado Springs: 220 events\n",
            "  4. Jaxon Engineering & Maintenance: 180 events\n",
            "  5. D49 - El Paso County School District 49: 125 events\n",
            "\n",
            "============================================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Export"
      ],
      "metadata": {
        "id": "Ztcgt71APodE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "output_path = '/content/drive/MyDrive/Work/BEA/2025 BEA Data Project Shared Folder/Data/(Main) Data Sources/Existing/PPBEA Pipeline/Cleaned/'\n",
        "os.makedirs(output_path, exist_ok=True)\n",
        "\n",
        "output_file = f'{output_path}PPBEA_Pipeline_2019-2025_Cleaned.csv'\n",
        "dfmain.to_csv(output_file, index=False)\n",
        "\n",
        "print(f\"Cleaned data saved to: {output_file}\")\n",
        "print(f\"Final shape: {dfmain.shape}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1SLRQHJzPs7E",
        "outputId": "24bd4371-9017-4012-d0dd-eb165b537124"
      },
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cleaned data saved to: /content/drive/MyDrive/Work/BEA/2025 BEA Data Project Shared Folder/Data/(Main) Data Sources/Existing/PPBEA Pipeline/Cleaned/PPBEA_Pipeline_2019-2025_Cleaned.csv\n",
            "Final shape: (9918, 19)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#"
      ],
      "metadata": {
        "id": "iXfh_ROYL3b8"
      }
    }
  ]
}